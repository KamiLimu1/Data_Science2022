{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#31394d'> Decision Trees Practice Exercise </font>\n",
    "\n",
    "It's time for you to build your own decision tree! For this exercise we'll be using the wine dataset from UCI Machine Learning Repository (and luckily included with sklearn). This dataset will let us try to predict the quality of wine (1 of 3 different levels) based on it's chemical composition. In our professional opinion, this homework pairs well with whatever wine you have at home :)\n",
    "\n",
    "We'll start by loading in the wine data set from sklearn and break it into X, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "wine.keys()\n",
    "\n",
    "X = pd.DataFrame(wine['data'], columns = wine['feature_names'])\n",
    "Y = pd.Series(wine['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280/od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "173    2\n",
       "174    2\n",
       "175    2\n",
       "176    2\n",
       "177    2\n",
       "Length: 178, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#D9C4B1'>Exercise: </font> Build a decision tree classifer for the wine data, and get a cross-validated score of it's accuracy. Hint use the `cross_val_score` function from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier()\n",
    "classifier=classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1, 1, 0, 1, 2, 2,\n",
       "       2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 0, 1, 2, 2, 0, 0,\n",
       "       1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8501424501424502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score=cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print('Accuracy: ',np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#D9C4B1'>Exercise: </font> Fit your tree model on the full data and visualize your decision tree using graphviz. The `draw_tree` function from class is included - if you have extra time try playing around with the options and understand what the function is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "def draw_tree(tree):\n",
    "    dot_data = export_graphviz(tree, out_file=None, \n",
    "                         feature_names=['alcohol','malic_acid', 'ash','alcalinity_of_ash','magnesium',\n",
    "                                        'total_phenols','flavanoids','nonflavanoid_phenols','proanthocyanins',\n",
    "                                        'color_intensity','hue','od280/od315_of_diluted_wines','proline'], \n",
    "                         class_names=['0', '1', '2'],\n",
    "                         filled=True, \n",
    "                         impurity=False,\n",
    "                         rounded=True,  \n",
    "                         special_characters=True)  \n",
    "    \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render('tree',view=True)\n",
    "    display(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#D9C4B1'>Exercise: </font> Try varying the max_depth parameter - what's the best depth you can find (try options on the range of 2 to 10)? Hint don't test one by one, automate the hyper-parameter tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {\"max_depth\": [2, 10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "classifier_cv=RandomizedSearchCV(classifier,params,cv=5)\n",
    "classifier_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tuned parameters: ', classifier_cv.best_params_)\n",
    "print('Best score: ', classifier_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#D9C4B1'>Exercise: </font> What features are the most important in your model? Hint take a peak at the `feature_importances_` variable in decision tree objects and how we accessed it in the class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=classifier.feature_importances_\n",
    "for x,y in enumerate(importance):\n",
    "    print('Feature ',x,': ',X.columns[x],', Score:',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features for the model are:\n",
    "- `proline`\n",
    "- `od280/od315_of_diluted_wines`\n",
    "- `flavanoids`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
